{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.corpus import words\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from nltk import pos_tag\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that processes the comments and returns clean_comments\n",
    "\n",
    "def text_preprocessing(data):\n",
    "\n",
    "    \n",
    "\n",
    "    #convert to lowercase\n",
    "    data['clean_comments'] = data['comments'].str.lower()\n",
    "\n",
    "    #removing empty columns\n",
    "    data['clean_comments'].replace('', np.nan, inplace=True)\n",
    "    data.dropna(subset=['clean_comments'], inplace=True)\n",
    "\n",
    "    #removing urls and html tags\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: re.sub(r'https?://\\S+www\\.\\S+', ' ', x))\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: re.sub(r'<.*?>', ' ', x))\n",
    "\n",
    "    #removing punctuations\n",
    "    punctuation = string.punctuation\n",
    "    data['clean_comments'] = data['clean_comments'].astype(str)\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: x.translate(str.maketrans('','',punctuation)))\n",
    "\n",
    "    #removing stopwords\n",
    "    STOPWORDS = set(stopwords.words('english'))\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: \" \".join([w for w in x.split() if w not in STOPWORDS]))\n",
    "\n",
    "    #remove non english words\n",
    "    #WORDS = set(words.words())\n",
    "    #data['clean_comments'] = data['clean_comments'].apply(lambda x: \" \".join(w for w in x.split() if w in WORDS))\n",
    "\n",
    "    #removing special characters\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: re.sub('[^a-zA-Z0-9]', ' ', x))\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: re.sub('\\s+', ' ', x))\n",
    "\n",
    "    #stemization\n",
    "    #ps = PorterStemmer()\n",
    "    #data['clean_comments'] = data['clean_comments'].apply(lambda x: \" \".join([ps.stem(w) for w in x.split()]))\n",
    "\n",
    "    #lemmatization and pos tagging\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    wordnet_map = {\"N\":wordnet.NOUN,\"V\":wordnet.VERB,\"J\":wordnet.ADJ,\"R\":wordnet.ADV}\n",
    "    data['clean_comments'] = data['clean_comments'].apply(lambda x: \" \".join([lemmatizer.lemmatize(w,wordnet_map.get(pos[0],wordnet.NOUN)) for w, pos in pos_tag(x.split())]))\n",
    "    \n",
    "    #removing empty columns\n",
    "    data['clean_comments'].replace('', np.nan, inplace=True)\n",
    "    data.dropna(subset=['clean_comments'], inplace=True)\n",
    "\n",
    "    #removing null value\n",
    "    #data['clean_comments'].dropna(how = any, axis = 0)\n",
    "\n",
    "    #word tokanize\n",
    "    #data['clean_comments'] = data['clean_comments'].apply(lambda x: word_tokenize(x))\n",
    "    #data\n",
    "    \n",
    "    #using globle variable i and modifying it after saving into csv\n",
    "    global y\n",
    "    data.to_csv(\"C:\\\\Users\\\\11ani\\\\OneDrive\\\\Desktop\\\\project 7th sem code\\\\clean_comments\\\\\"+str(y)+\"clean.csv\")\n",
    "    y = y+1\n",
    "    print(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              comments  sentiments  \\\n",
      "0    Nepal was a leading country in material indust...           1   \n",
      "1    I never knew we had such a early head start in...           1   \n",
      "2    My dad owned a garment factory during that tim...           1   \n",
      "3    Loved the video bro , you must now be consiste...           1   \n",
      "4    Was garment industry the only industry in Nepa...           1   \n",
      "..                                                 ...         ...   \n",
      "171                                        haet....!!!           1   \n",
      "172                                                HOR           1   \n",
      "173                                               Ghjn           1   \n",
      "174  Bro resham Chaudhary maa euta video banauna yo...           1   \n",
      "176  Bro resham Chaudhary maa euta video banauna yo...           1   \n",
      "\n",
      "                                        clean_comments  \n",
      "0    nepal lead country material industry sad see c...  \n",
      "1    never know early head start garment industry u...  \n",
      "2    dad own garment factory time use feel proud se...  \n",
      "3    love video bro must consistent many u addictiv...  \n",
      "4    garment industry industry nepalwhat industry w...  \n",
      "..                                                 ...  \n",
      "171                                               haet  \n",
      "172                                                hor  \n",
      "173                                               ghjn  \n",
      "174  bro resham chaudhary maa euta video banauna yo...  \n",
      "176  bro resham chaudhary maa euta video banauna yo...  \n",
      "\n",
      "[160 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "y = 0\n",
    "\n",
    "for i in range(1):\n",
    "    data = pd.read_csv(\"C:\\\\Users\\\\11ani\\\\OneDrive\\\\Desktop\\\\project 7th sem code\\\\raw_comments\\\\\"+str(i)+\"raw.csv\", index_col=[0])\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b9de5f633baef838eda09087c377b407887e2414fdad0aa392eeb39aea32887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

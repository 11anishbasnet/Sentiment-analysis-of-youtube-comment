{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>sentiments</th>\n",
       "      <th>clean_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thanks a lot for the tutorial! It helps a lot!...</td>\n",
       "      <td>1</td>\n",
       "      <td>['thanks', 'lot', 'tutorial', 'lot', 'definite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this is extremely helpful mate! keep making su...</td>\n",
       "      <td>1</td>\n",
       "      <td>['extremely', 'helpful', 'mate', 'keep', 'make...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>can't we just use pytube to print the title?</td>\n",
       "      <td>0</td>\n",
       "      <td>['cant', 'use', 'print', 'title']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi, is it legal to scrap youtube comments ? Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hi', 'legal', 'scrap', 'thanks']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is the code of this Video available? thanks</td>\n",
       "      <td>1</td>\n",
       "      <td>['code', 'video', 'available', 'thanks']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>It is sayinf that &gt;= does not work with int an...</td>\n",
       "      <td>0</td>\n",
       "      <td>['work', 'non', 'type', 'help']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>it works Thanks but it is very slow. Can you d...</td>\n",
       "      <td>1</td>\n",
       "      <td>['work', 'thanks', 'slow', 'via']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Can we scrape emails from these comments</td>\n",
       "      <td>0</td>\n",
       "      <td>['scrape']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Where you run this code</td>\n",
       "      <td>0</td>\n",
       "      <td>['run', 'code']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i am so  happy after watching this video. Than...</td>\n",
       "      <td>1</td>\n",
       "      <td>['happy', 'watch', 'video', 'much', 'content']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hey sir, how do you take 200 comments first?</td>\n",
       "      <td>0</td>\n",
       "      <td>['hey', 'sir', 'take', 'first']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hey, nice to meet you! I just found your chann...</td>\n",
       "      <td>1</td>\n",
       "      <td>['hey', 'nice', 'meet', 'find', 'channel', 'lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>I am getting this key error: \\r\\nKeyError: &lt;_S...</td>\n",
       "      <td>0</td>\n",
       "      <td>['get', 'key', 'error', 'please', 'help']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I DO NOT UNDERSTAND</td>\n",
       "      <td>1</td>\n",
       "      <td>['understand']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Love you, my respected brother, although the m...</td>\n",
       "      <td>1</td>\n",
       "      <td>['love', 'brother', 'although', 'method', 'get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Thank you brother for video</td>\n",
       "      <td>1</td>\n",
       "      <td>['thank', 'brother', 'video']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Bruh, can you learn english before doing video...</td>\n",
       "      <td>0</td>\n",
       "      <td>['learn', 'language']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comments  sentiments  \\\n",
       "0   Thanks a lot for the tutorial! It helps a lot!...           1   \n",
       "1   this is extremely helpful mate! keep making su...           1   \n",
       "2        can't we just use pytube to print the title?           0   \n",
       "3   Hi, is it legal to scrap youtube comments ? Th...           0   \n",
       "4         Is the code of this Video available? thanks           1   \n",
       "5   It is sayinf that >= does not work with int an...           0   \n",
       "6   it works Thanks but it is very slow. Can you d...           1   \n",
       "7            Can we scrape emails from these comments           0   \n",
       "8                             Where you run this code           0   \n",
       "9   i am so  happy after watching this video. Than...           1   \n",
       "10       Hey sir, how do you take 200 comments first?           0   \n",
       "11  Hey, nice to meet you! I just found your chann...           1   \n",
       "12  I am getting this key error: \\r\\nKeyError: <_S...           0   \n",
       "13                                I DO NOT UNDERSTAND           1   \n",
       "14  Love you, my respected brother, although the m...           1   \n",
       "15                        Thank you brother for video           1   \n",
       "16  Bruh, can you learn english before doing video...           0   \n",
       "\n",
       "                                       clean_comments  \n",
       "0   ['thanks', 'lot', 'tutorial', 'lot', 'definite...  \n",
       "1   ['extremely', 'helpful', 'mate', 'keep', 'make...  \n",
       "2                   ['cant', 'use', 'print', 'title']  \n",
       "3                  ['hi', 'legal', 'scrap', 'thanks']  \n",
       "4            ['code', 'video', 'available', 'thanks']  \n",
       "5                     ['work', 'non', 'type', 'help']  \n",
       "6                   ['work', 'thanks', 'slow', 'via']  \n",
       "7                                          ['scrape']  \n",
       "8                                     ['run', 'code']  \n",
       "9      ['happy', 'watch', 'video', 'much', 'content']  \n",
       "10                    ['hey', 'sir', 'take', 'first']  \n",
       "11  ['hey', 'nice', 'meet', 'find', 'channel', 'lo...  \n",
       "12          ['get', 'key', 'error', 'please', 'help']  \n",
       "13                                     ['understand']  \n",
       "14  ['love', 'brother', 'although', 'method', 'get...  \n",
       "15                      ['thank', 'brother', 'video']  \n",
       "16                              ['learn', 'language']  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import math\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "data = pd.read_csv('test.csv', index_col=[0])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = data['clean_comments'].values\n",
    "labels = data['sentiments'].values\n",
    "encoder = LabelEncoder()\n",
    "encoded_labels = encoder.fit_transform(labels)\n",
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(reviews, encoded_labels, stratify = encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\11ani\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(max_features = 3000)\n",
    "X = vec.fit_transform(train_sentences)\n",
    "vocab = vec.get_feature_names()\n",
    "X = X.toarray()\n",
    "word_counts = {}\n",
    "for l in range(2):\n",
    "    word_counts[l] = defaultdict(lambda: 0)\n",
    "for i in range(X.shape[0]):\n",
    "    l = train_labels[i]\n",
    "    for j in range(len(vocab)):\n",
    "        word_counts[l][vocab[j]] += X[i][j]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace_smoothing(n_label_items, vocab, word_counts, word, text_label):\n",
    "    a = word_counts[text_label][word] + 1\n",
    "    b = n_label_items[text_label] + len(vocab)\n",
    "    return math.log(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_label(x, y, labels):\n",
    "    data = {}\n",
    "    for l in labels:\n",
    "        data[l] = x[np.where(y == l)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x, y, labels):\n",
    "    n_label_items = {}\n",
    "    log_label_priors = {}\n",
    "    n = len(x)\n",
    "    grouped_data = group_by_label(x, y, labels)\n",
    "    for l, data in grouped_data.items():\n",
    "        n_label_items[l] = len(data)\n",
    "        log_label_priors[l] = math.log(n_label_items[l] / n)\n",
    "    return n_label_items, log_label_priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(n_label_items, vocab, word_counts, log_label_priors, labels, x):\n",
    "    result = []\n",
    "    for text in x:\n",
    "        label_scores = {l: log_label_priors[l] for l in labels}\n",
    "        words = set(text)\n",
    "        for word in words:\n",
    "            if word not in vocab: continue\n",
    "            for l in labels:\n",
    "                log_w_given_l = laplace_smoothing(n_label_items, vocab, word_counts, word, l)\n",
    "                label_scores[l] += log_w_given_l\n",
    "        result.append(max(label_scores, key=label_scores.get))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction on test set :  0.4\n"
     ]
    }
   ],
   "source": [
    "labels = [0,1]\n",
    "n_label_items, log_label_priors = fit(train_sentences,train_labels,labels)\n",
    "pred = predict(n_label_items, vocab, word_counts, log_label_priors, labels, test_sentences)\n",
    "print(\"Accuracy of prediction on test set : \", accuracy_score(test_labels,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b9de5f633baef838eda09087c377b407887e2414fdad0aa392eeb39aea32887"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
